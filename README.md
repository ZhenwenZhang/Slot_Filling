# Research Advances In Semantic Slot Filling 

This repo mainly summary latest research advances on semantic slot filling.

# Performance

| Methods | F1 | Published Address |Paper|
| ------ | ------ |------ |------------ |
| Simple RNN | 0.9411 |Interspeech, 2013|[Link](#1.)|
| CNN-CRF | 0.9435 | ASRU,2013 |Link|
|  LSTM | 0.9485 |SLT Workshop,2014 |Link|
| RNN-SOP | 0.9489 |NIPS Workshop,2015 |Link|
| Deep LSTM | 0.9508  | SLT Workshop,2014|Link|
| RNN-EM | 0.9525 |arXiv,2015 |Link|
| Bi-RNN with ranking loss | 0.9547| ICASSP,2016|Link|
| Sequential CNN | 0.9561|Interspeech,2016 |Link|
| Encoder-labeler Deep LSTM | 0.9566| EMNLP, 2016|Link|
| BiLSTM-LSTM (focus) | 0.9579| ICASSP, 2017|Link|
| Neural Sequence Chunking | 0.9586 |AAAI，2017 |Link|

# Related Papers

#### 1. [Zhai, Feifei, et al. "Neural Models for Sequence Chunking." AAAI. 2017.](https://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/download/14776/14262)

[Zhu, Su, and Kai Yu. "Encoder-decoder with focus-mechanism for sequence labelling based spoken language understanding." 2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2017.](https://ieeexplore.ieee.org/abstract/document/7953243)

[Vu, Ngoc Thang. "Sequential convolutional neural networks for slot filling in spoken language understanding." arXiv preprint arXiv:1606.07783 (2016).](https://arxiv.org/abs/1606.07783.pdf)


[Vu, Ngoc Thang, et al. "Bi-directional recurrent neural network with ranking loss for spoken language understanding." Acoustics, Speech and Signal Processing (ICASSP), 2016 IEEE International Conference on. Ieee, 2016.](https://ieeexplore.ieee.org/abstract/document/7472841)


 [Peng, Baolin, and Kaisheng Yao. "Recurrent neural networks with external memory for language understanding." arXiv preprint arXiv:1506.00195 (2015).](https://arxiv.org/abs/1506.00195.pdf)

1.[Peng, B., and Yao, K. 2015. Recurrent neural networks with external memory for language understanding.arXiv.](https://ieeexplore.ieee.org/abstract/document/7078572)


1.[Liu, B., and Lane, I. 2015. Recurrent neural network structured output prediction for spoken language understanding. In NIPS Workshop.](https://pdfs.semanticscholar.org/b75b/59f38c874a920102834c9e218c960fc35c81.pdf)


1.[Yao, Kaisheng, et al. "Spoken language understanding using long short-term memory neural networks." Spoken Language Technology Workshop (SLT), 2014 IEEE. IEEE, 2014.](https://groups.csail.mit.edu/sls/publications/2014/Zhang_SLT_2014.pdf)

1.["Recurrent neural networks for language understanding."](https://www.isca-speech.org/archive/archive_papers/interspeech_2013/i13_2524.pdf)

2.[ Mesnil, Grégoire, et al. "Using recurrent neural networks for slot filling in spoken language understanding." IEEE/ACM Transactions on Audio, Speech, and Language Processing 2015](https://ieeexplore.ieee.org/abstract/document/6998838)

3.[ Kurata, Gakuto, et al. "Leveraging sentence-level information with encoder lstm for semantic slot filling." EMNLP 2016](https://arxiv.org/abs/1601.01530.pdf)

4.[ Hakkani-Tür, Dilek, et al. "Multi-Domain Joint Semantic Frame Parsing Using Bi-Directional RNN-LSTM." Interspeech 2016](https://pdfs.semanticscholar.org/d644/ae996755c803e067899bdd5ea52498d7091d.pdf)

5.[ Zhang, Xiaodong, and Houfeng Wang. "A Joint Model of Intent Determination and Slot Filling for Spoken Language Understanding." IJCAI 2016](https://www.ijcai.org/Proceedings/16/Papers/425.pdf)

6.[ Liu, Bing, and Ian Lane. "Attention-based recurrent neural network models for joint intent detection and slot filling." Interspeech 2016](https://arxiv.org/abs/1609.01454)

7.[ Constantin, Stefan, Jan Niehues, and Alex Waibel. "Multi-task learning to improve natural language understanding." 2018](https://arxiv.org/abs/1812.06876.pdf)

8.[ Zhao, Lin, and Zhe Feng. "Improving Slot Filling in Spoken Language Understanding with Joint Pointer and Attention." ACL 2018](http://www.aclweb.org/anthology/P18-2068)

9.[ Gong, Yu, et al. "Deep Cascade Multi-task Learning for Slot Filling in Online Shopping Assistant." 2019](http://www.cs.sjtu.edu.cn/~kzhu/papers/kzhu-slot.pdf)
